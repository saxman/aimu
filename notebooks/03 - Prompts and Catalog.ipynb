{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prompt-notebook-title",
   "metadata": {},
   "source": [
    "# 03 - Prompts and Catalog\n",
    "\n",
    "Demonstrate various usage scenarios for the AIMU Prompt and PromptCatalog classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-a-header",
   "metadata": {},
   "source": [
    "## A - Creating and Managing Prompts\n",
    "\n",
    "The Prompt class is a SQLAlchemy model that stores prompt data including versioning, metrics, and mutation/reasoning prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimu.prompts import Prompt, PromptCatalog\n",
    "\n",
    "# Create a new prompt instance\n",
    "prompt = Prompt(\n",
    "    prompt=\"You are a helpful assistant that provides clear and concise answers.\",\n",
    "    model_id=\"gpt-4\",\n",
    "    version=1,\n",
    "    mutation_prompt=\"Vary the tone to be more friendly\",\n",
    "    reasoning_prompt=\"Think step by step before answering\",\n",
    "    metrics={\"accuracy\": 0.95, \"response_time\": 1.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-b-header",
   "metadata": {},
   "source": [
    "## B - Setting up a PromptCatalog\n",
    "\n",
    "The PromptCatalog class provides a SQLite-backed database for storing and retrieving prompts. It handles database connections and provides methods for CRUD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create a temporary database file for this example\n",
    "temp_db = tempfile.NamedTemporaryFile(suffix=\".db\", delete=False)\n",
    "temp_db.close()\n",
    "\n",
    "# Initialize the catalog with the database path\n",
    "catalog = PromptCatalog(temp_db.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-c-header",
   "metadata": {},
   "source": [
    "## C - Storing Prompts\n",
    "\n",
    "You can store prompts in the catalog for later retrieval. Each prompt can be associated with a model ID and version for organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "store-prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the first prompt\n",
    "catalog.store_prompt(prompt)\n",
    "\n",
    "# Create and store additional prompts for the same model\n",
    "prompt_v2 = Prompt(\n",
    "    prompt=\"You are a helpful assistant that provides detailed explanations with examples.\",\n",
    "    model_id=\"gpt-4\",\n",
    "    version=2,\n",
    "    mutation_prompt=\"Add more technical details\",\n",
    "    reasoning_prompt=\"Provide reasoning with examples\",\n",
    "    metrics={\"accuracy\": 0.97, \"response_time\": 1.5}\n",
    ")\n",
    "\n",
    "catalog.store_prompt(prompt_v2)\n",
    "\n",
    "# Create prompts for a different model\n",
    "claude_prompt = Prompt(\n",
    "    prompt=\"You are Claude, an AI assistant created by Anthropic.\",\n",
    "    model_id=\"claude-3\",\n",
    "    version=1,\n",
    "    mutation_prompt=\"Be more conversational\",\n",
    "    reasoning_prompt=\"Consider multiple perspectives\",\n",
    "    metrics={\"accuracy\": 0.93, \"response_time\": 0.8}\n",
    ")\n",
    "\n",
    "catalog.store_prompt(claude_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-d-header",
   "metadata": {},
   "source": [
    "## D - Retrieving Prompts\n",
    "\n",
    "The catalog provides methods to retrieve the latest prompt for a model, or all prompts for a model ordered by version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrieve-prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the latest prompt for GPT-4\n",
    "latest_gpt4 = catalog.retrieve_last(\"gpt-4\")\n",
    "print(f\"Latest GPT-4 prompt (v{latest_gpt4.version}): {latest_gpt4.prompt}\")\n",
    "print(f\"Metrics: {latest_gpt4.metrics}\")\n",
    "print()\n",
    "\n",
    "# Retrieve all prompts for GPT-4\n",
    "all_gpt4 = catalog.retrieve_all(\"gpt-4\")\n",
    "print(f\"All GPT-4 prompts ({len(all_gpt4)} total):\")\n",
    "for p in all_gpt4:\n",
    "    print(f\"  v{p.version}: {p.prompt[:50]}...\")\n",
    "print()\n",
    "\n",
    "# Retrieve the latest prompt for Claude\n",
    "latest_claude = catalog.retrieve_last(\"claude-3\")\n",
    "print(f\"Latest Claude prompt: {latest_claude.prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-e-header",
   "metadata": {},
   "source": [
    "## E - Managing Model IDs\n",
    "\n",
    "You can retrieve a list of all model IDs that have prompts stored in the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-model-ids",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all model IDs in the catalog\n",
    "model_ids = catalog.retrieve_model_ids()\n",
    "print(f\"Models in catalog: {model_ids}\")\n",
    "\n",
    "# Show summary of prompts for each model\n",
    "for model_id in model_ids:\n",
    "    prompts = catalog.retrieve_all(model_id)\n",
    "    print(f\"  {model_id}: {len(prompts)} prompt(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-f-header",
   "metadata": {},
   "source": [
    "## F - Working with Prompt Hierarchies\n",
    "\n",
    "Prompts can have parent-child relationships through the parent_id field, allowing you to track prompt evolution and mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a child prompt that references the parent\n",
    "parent_prompt = catalog.retrieve_last(\"gpt-4\")\n",
    "\n",
    "child_prompt = Prompt(\n",
    "    parent_id=parent_prompt.id,\n",
    "    prompt=\"You are a helpful assistant that provides detailed explanations with examples and references.\",\n",
    "    model_id=\"gpt-4\",\n",
    "    version=3,\n",
    "    mutation_prompt=\"Add citations and references\",\n",
    "    reasoning_prompt=\"Provide reasoning with examples and sources\",\n",
    "    metrics={\"accuracy\": 0.98, \"response_time\": 1.8}\n",
    ")\n",
    "\n",
    "catalog.store_prompt(child_prompt)\n",
    "print(f\"Created child prompt with parent ID: {child_prompt.parent_id}\")\n",
    "\n",
    "# Verify the relationship\n",
    "updated_latest = catalog.retrieve_last(\"gpt-4\")\n",
    "print(f\"Latest prompt version: {updated_latest.version}\")\n",
    "print(f\"Parent ID: {updated_latest.parent_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-g-header",
   "metadata": {},
   "source": [
    "## G - Cleaning Up\n",
    "\n",
    "You can delete all prompts for a specific model when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show current state\n",
    "print(\"Before cleanup:\")\n",
    "for model_id in catalog.retrieve_model_ids():\n",
    "    count = len(catalog.retrieve_all(model_id))\n",
    "    print(f\"  {model_id}: {count} prompt(s)\")\n",
    "print()\n",
    "\n",
    "# Delete all GPT-4 prompts\n",
    "deleted_count = catalog.delete_all(\"gpt-4\")\n",
    "print(f\"Deleted {deleted_count} GPT-4 prompts\")\n",
    "print()\n",
    "\n",
    "# Show state after cleanup\n",
    "print(\"After cleanup:\")\n",
    "for model_id in catalog.retrieve_model_ids():\n",
    "    count = len(catalog.retrieve_all(model_id))\n",
    "    print(f\"  {model_id}: {count} prompt(s)\")\n",
    "\n",
    "# Clean up the temporary database file\n",
    "del catalog  # This will close the session\n",
    "os.unlink(temp_db.name)\n",
    "print(f\"\\nCleaned up temporary database: {temp_db.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
